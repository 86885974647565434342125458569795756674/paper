# Abstract

由于内存限制，非常大的模型可能很难训练。我们提出了训练超大型变压器模型的技术，并实现了一种简单、有效的层内模型并行方法，使训练具有数十亿个参数的变压器模型成为可能。我们的方法不需要新的编译器或库更改，与管道模型并行性正交并互补，并且可以通过在原生PyTorch中插入一些通信操作来完全实现。

# Introduction

