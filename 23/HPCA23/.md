[Main Program – HPCA 2023 (hpca-conf.org)](https://hpca-conf.org/2023/main-program/)



MPress Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism

流水线，d2d(压力大到压力小，生存间隔短),c2g,后几层优先考虑重计算

给每个tensor赋予一种内存技术

先赋予c2g(生存间隔长可重叠)、重计算（计算开销小于等于c2g不能被重叠的开销）

再替换成d2d

ViTALiTy: Unifying Low-rank and Sparse Approximation for Vision Transformer Acceleration with a Linear Taylor Attention

CTA: Hardware-Software Co-design for Compressed Token Attention Mechanism

Chimera: An Analytical Optimizing Framework for Effective Compute-intensive Operators Fusion

Tensor Movement Orchestration In Multi-GPU Training Systems



Trans-FW: Short Circuiting Page Table Walk in Multi-GPU Systems via Remote Forwarding
