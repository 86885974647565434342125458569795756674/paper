# ABSTRACT

现有的解决方案，如数据和模型并行，在获得计算、通信和开发效率的同时，在将这些模型适应有限的设备内存方面表现出基本的局限性。我们开发了一种新颖的解决方案，零冗余优化器(Zero)，以优化内存，大大提高了训练速度，同时增加了可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保持了低通信量和高计算粒度，使我们能够以持续的高效率按比例缩放模型大小。我们对内存需求和通信量的分析表明:使用当今的硬件，ZeRO有可能扩展到超过1万亿个参数。模型尺寸增加了8倍，可实现性能增加了10倍。在可用性方面，ZeRO可以训练多达13B个参数的大型模型(例如，比威天GPT 8.3B和T5 11B更大)，而不需要模型并行性。研究人员利用ZeRO的系统突破创建了图灵- nlg，这是当时世界上最大的语言模型(17B个参数)，其准确性打破了纪录。

# EXTENDED INTRODUCTION

基本数据并行性(DP)不会减少每个设备的内存，runs out of memory for models with more than 1.4B parameters on GPUs with 32 GB memory when trained using common settings like mixed precision and ADAM optimizer。Pipeline Parallelism (PP)， Model Parallelism (MP)， CPU-Offloading等，在功能，可用性以及内存和计算/通信效率之间进行权衡，所有这些都对速度和规模的训练至关重要。

目前文献中最大的模型，11B T5模型[5]和MegatronLM 8.3B[4]，都是由模型并行性驱动的，分别在Mesh-Tensorflow[7]和Megatron-LM[4]中实现。然而，MP不能扩展到超出这些模型大小的范围。MP垂直拆分模型，将每一层的计算和参数跨多个设备划分，要求每一层之间进行大量通信。因此，它们在gpu间通信带宽高的单个节点内工作良好，但在单个节点之外效率会迅速下降[4]。

首先分析了现有系统在模型训练上的全部内存消耗，并将其分为两部分:1)对于大型模型，大部分内存被模型状态占用，其中包括优化器状态(如Adam[6]中的动量和方差)、梯度和参数。2)剩余的内存被激活、临时缓冲区和不可用的碎片内存所消耗，我们将其统称为剩余状态。我们开发了ZeRO - （ZeRO冗余优化器）-在获得高计算和通信效率的同时，优化内存效率。

## Optimizing Model State Memory

模型状态通常在训练过程中消耗最大的内存，但是现有的方法(如DP和MP)并不能提供令人满意的解决方案。DP具有良好的计算/通信效率，但内存效率较差，而MP具有较差的计算/通信效率。更具体地说，DP在所有数据并行进程中复制整个模型状态，导致冗余内存消耗;MP对这些状态进行分区以获得较高的内存效率;但通常会导致过于细粒度的计算和昂贵的通信，从而降低扩展效率。（？）所有这些方法都静态地维护整个训练过程中所需的所有模型状态，即使在训练过程中并非所有模型状态都是必需的。我们开发了ZeRO-DP，零功率数据并行，在实现DP的计算/通信效率的同时实现MP的内存效率。ZeRO-DP通过划分模型状态而不是复制模型状态来消除数据并行进程之间的内存状态冗余，并在训练期间使用动态通信调度保留DP的计算粒度和通信量，从而保持计算/通信效率。

ZeRO-DP has three main optimization stages (as depicted in Figure 1), which correspond to the partitioning of optimizer states, gradients, and parameters (Sec. V). When enabled
cumulatively:

1) Optimizer State Partitioning (Pos): 4x memory reduction, same communication volume as DP;
2) Add Gradient Partitioning (Pos+g): 8x memory reduction, same communication volume as DP;
3) Add Parameter Partitioning (Pos+g+p): Memory reduction is linear with DP degree Nd. For example, splitting across 64 GPUs (Nd = 64) will yield a 64x memory reduction. There
is a modest 50% increase in communication volume.

![](zero-dp.png)

ZeRO-DP消除了内存冗余，并使集群的全部聚合内存容量可用。

## Optimizing Residual State Memory

After ZeRO-DP提高了模型状态的内存效率，临时缓冲区和不可用的内存片段可能成为次要内存瓶颈。我们开发了ZeRO-R来优化这三个因素分别消耗的剩余内存。

1)对于激活(在向前传递期间存储以便执行向后传递)，我们注意到检查点[8]有帮助，但对于大型模型来说是不够的。ZeRO-R optimizes activation memory by identifying and removing activation
replication in existing MP approaches through activation partitioning. It also offloads activations to CPU when appropriate

2) ZeRO-R为临时缓冲区定义合适的大小，以达到内存和计算效率的平衡。
3) We observe fragmented memory during training due to variations in the lifetime of different tensors. 由于碎片导致的连续内存缺乏可能导致内存分配失败，即使有足够的空闲内存可用。ZeRO-R基于张量的不同生命周期主动管理内存，防止内存碎片。

ZeRO- dp和ZeRO- r结合在一起形成了一个强大的深度学习记忆优化系统，我们统称为ZeRO。

由于ZeRO消除了DP中的内存效率低下，因此很自然地要问:我们还需要MP吗?什么时候需要?ZeRO如何与MP一起工作?With ZeRO, MP becomes a less attractive option for the purpose of fitting
large models alone.在减少每个设备的内存占用方面，ZeRO-DP至少与MP一样有效，有时在MP不能平均划分模型时更有效。它还具有相当或更好的缩放效率。此外，数据并行性非常容易使用，广泛适用于不同的工作负载，而今天的MP方法通常需要模型开发人员进行一些工作来修改他们的模型，系统开发人员需要计算出分布式操作符，而像Megatron-LM这样的现有工作只支持有限的一组操作符和模型。

话虽如此，我们仍然希望利用MP: i)当与ZeRO-R一起使用时，MP可以减少非常大的模型的激活内存占用。ii)对于较小的模型，激活内存不是问题，当单独使用DP的聚合批处理大小太大而无法具有良好的收敛性时，MP也可以有好处在这种情况下，可以将ZeRO与MP结合起来，使模型具有可接受的聚合批大小。

We show that ZeRO can be combined with MP, resulting in a max theoretical memory reduction of Nd×Nm times on each device with a DP degree of Nd and MP degree of Nm.这允许我们在1024个gpu上使用16路模型并行性(在每个DGX2节点内)和跨节点的64路数据并行性拟合一个万亿参数模型，并使用适度的批处理大小有效地运行它

## Implementation & Evaluation

The complete set of optimizations in ZeRO could allow us to run models with trillion parameters on the high-end hardware cluster today。however, the hardware compute capacity is still too limited and training time can be impractically long(>1 year).our focus for this implementation is to efficiently support models with 10x parameters (∼100B
parameters) than state-of-the-art (SOTA) while still being within reach of the compute capabilities of current hardware.（最好模型的10倍）

我们在ZeRO中实现并评估了一个名为ZeRO- 100b的优化子集，即Pos+g的ZeRO- dp加上ZeRO- r，这使我们能够实现这一目标。

现有系统如单独使用威震天，无法高效扩展超过20B参数。与SOTA相比，模型大小增加了8倍以上。

对于相同的模型大小，这比SOTA的训练速度提高了10倍以上。

当我们将gpu数量增加一倍时，性能会增加一倍以上。这是ZeRODP的一个属性，当我们增加DP度时，它减少了模型状态的内存占用，使我们能够适应每个GPU更大的批处理大小，从而获得更好的性能。

ZeRO-100B使数据科学家能够训练具有多达13B个参数的模型，而无需任何需要模型重构的MP或PP。（只要DP)现有系统(例如PyTorch分布式数据并行)使用1.4B参数模型时会耗尽内存。

ZeRO超越了Turing-NLG[10]，后者是当时最大的语言模型，拥有17B个参数和破纪录的精度。

We share ZeRO as a part of our open source DL training optimization library — DeepSpeed

# RELATED WORK

## Data, Model and Pipeline Parallelism

每个进程在不同的数据样本子集上执行前向和后向传播，并使用进程间的平均梯度在本地更新模型。当模型不适合设备内存时，模型并行性(MP)[7]、[4]、[11]和流水线并行性(PP)[12]、[13]分别以垂直和水平的方式将模型拆分到进程之间。(?)

PP splits a model horizontally across layers running each partition on a different device and use micro-batching to hide the pipeline bubble. Model functionalities such as tied-weights and batch-normalization are difficult to implement due to horizontal splitting and micro-batching, respectively.G-pipe[12]对模型参数和总激活进行分区，但需要与管道分区数量成比例的批大小来隐藏管道气泡。大的批处理大小会影响收敛速度，同时还需要大量内存来存储激活。PipeDream中，PP的另一种实现[14]保留了过期参数的多个副本在不显著增加批处理大小的情况下隐藏管道气泡，从而降低内存效率。此外，实现不等同于标准的深度学习训练，并且对训练收敛有影响。 In contrast, ZeRO obtains the same or better memory efficiency than PP without incurring functionality, performance and convergence related restrictions of PP

## Non-parallelism based approach to reduce memory

1)减少激活内存:通过压缩[15]、激活检查点[8]、[16]或实时分析[17]来减少激活的内存占用。这些努力是互补的，可以与ZeRO一起工作。实际上，ZeRO-R中的激活内存减少与激活检查点并行工作(?)

2) CPU卸载:[18]、[19]利用当今计算节点的异构特性，分别通过算法设计、虚拟化内存将模型状态卸载到CPU内存。高达50%的训练时间可以花在GPU-CPU-GPU传输上[18]。ZeRO的不同之处在于，它在不将模型状态存储到CPU内存的情况下显著减少了内存消耗，CPU内存的带宽由于PCI-E而受到严重限制。在极少数情况下，ZeRO-R可能会卸载非常大的模型的激活检查点，以提高性能(详细信息请参见第VI-A节)。[20]使用图形重写来卸载激活到CPU内存，但不减少模型状态所需的内存。
3) Memory Efficient Optimizer:[21]，[22]侧重于通过保持模型参数和梯度的粗粒度统计来减少自适应优化方法的内存消耗，这对模型收敛保证有潜在的影响。ZeRO与这些努力是正交的，它的优化不会改变模型优化方法或影响模型收敛，而是有效地减少优化器状态和每个设备的梯度的内存占用。

##  Training Optimizers

自适应优化方法[23]，[6]，[24]，[25]对于实现SOTA性能和准确性对于大型模型的有效模型训练至关重要。与SGD相比，通过为每个模型参数和梯度维护细粒度的一阶和二阶统计信息，以消耗大量内存为代价。ZeRO可以在数量级上减少这些优化器的内存占用，使这些复杂的优化方法适用于在具有适度设备内存的硬件上训练大型模型。它还使开发和使用更复杂、更需要内存的优化器成为可能，这些优化器可能具有更好的收敛性。

#  WHERE DID ALL THE MEMORY GO?

## Model States: Optimizer States, Gradients and Parameters

大部分设备内存在训练期间被模型状态消耗。以Adam[6]为例，他是最流行的深度学习训练优化器之一。Adam需要存储两个优化器状态，i)时间平均动量和ii)梯度方差来计算更新。要用ADAM训练模型，必须有足够的内存来保存梯度的动量和方差的副本。此外，还需要有足够的内存来存储梯度和权重本身。在这三种类型的参数相关张量中，优化器状态通常消耗最多的内存，特别是在应用混合精度训练时

在当前一代NVIDIA gpu上训练大型模型的最先进方法是通过混合精度(fp16/32)训练[26]，其中参数和激活被存储为fp16，从而能够在这些gpu上使用高吞吐量张量核心单元[27]。在混合精度训练中，前向和后向传播都使用fp16权值和激活来执行。However, to effectively compute and apply the
updates at the end of the backward propagation, the mixed-precision optimizer keeps an fp32 copy of the parameters as well as an fp32 copy of all the other optimizer states.

使用Adam对具有Ψ参数的模型进行混合精度训练，需要足够的内存来保存参数和梯度的fp16副本，内存需求分别为2Ψ和2Ψ字节。此外，它还需要保存优化器状态:参数、动量和方差的fp32副本，内存需求分别为4Ψ、4Ψ和4Ψ字节。让我们使用K来表示优化器状态的内存乘数，也就是说，存储它们所需的额外内存是KΨ字节。混合精度亚当的K = 12。这导致2Ψ+2Ψ+KΨ = 16Ψ字节的内存需求。对于具有1.5亿个参数的GPT-2这样的模型，这将导致至少24gb的内存需求，这远远高于仅保存fp16参数所需的微薄的3gb内存。

## Residual Memory Consumption

激活检查点(或激活重计算)是一种常用的方法，可以将激活内存减少大约为总激活的平方根，而代价是33%的重新计算开销[8]。尽管激活内存显著减少，但对于更大的模型，即使使用激活检查点，激活内存也会增长得相当大。

Operations such as gradient all-reduce, or gradient norm computation tend to fuse all the gradients into a single flattened buffer before applying the operation in an effort to improve
throughput. For example, the bandwidth of all-reduce across devices improves with large message sizes. While the gradient themselves are usually stored as fp16 tensors, the fused buffer can be an fp32 tensor depending on the operation.

当训练非常大的模型时，我们观察到明显的内存碎片，在某些极端情况下，超过30%的内存仍然可用，从而导致内存不足问题。

# ZeRO: INSIGHTS AND OVERVIEW

ZeRO能够在保持效率的同时减少内存占用。效率是这里的关键:如果没有这个约束，将所有参数状态移动到CPU内存或任意增加MP度等简单的解决方案可以减少内存占用

# Insights and Overview: ZeRO-DP

ZeRO powered DP is based on three key insights:
a) DP has better scaling efficiency than MP because MP reduces the granularity of the computation while also increasing the communication overhead.(?怎么感觉是tensor) Beyond a certain point, lower computational granularity reduces the efficiency per GPU, while the increased communication overhead, hiders the scalability across GPUs, especially when crossing node boundaries. On the contrary, DP has both higher computational
granularity and lower communication volume, allowing for much higher efficiency.

b) DP是内存效率低下的，因为模型状态被冗余地存储在所有数据并行进程中。相反，MP对模型状态进行分区以获得内存效率。

c) DP和MP都保留了整个训练过程中所需的所有模型状态，但并非所有状态都是必需的。例如，每层对应的参数只在层的正向传播和反向传播时才需要。

基于这些见解，ZeRO-DP在保持DP的训练效率的同时，实现了MP的记忆效率。





# 。

模型状态：优化器状态、梯度、参数

剩余状态：激活、临时buffer、内存碎片

zero-dp:将模型状态平分

zero-r:去掉MP的激活冗余、激活offload、临时缓冲区定义合适的大小、基于张量的不同生命周期主动管理内存